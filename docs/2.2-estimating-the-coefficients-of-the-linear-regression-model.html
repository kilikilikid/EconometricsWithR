<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<title>2.2 Estimating the Coefficients of the Linear Regression Model | Introduction to Econometrics with R</title>
<meta name="description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
<meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

<meta property="og:title" content="2.2 Estimating the Coefficients of the Linear Regression Model | Introduction to Econometrics with R" />
<meta property="og:type" content="book" />
<meta property="og:image" content="https://www.econometrics-with-r.org//images/cover.png" />
<meta property="og:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
<meta name="github-repo" content="mca91/EconometricsWithR" />

<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="2.2 Estimating the Coefficients of the Linear Regression Model | Introduction to Econometrics with R" />

<meta name="twitter:description" content="Beginners with little background in statistics and econometrics often have a hard time understanding the benefits of having programming skills for learning and applying Econometrics. ‘Introduction to Econometrics with R’ is an interactive companion to the well-received textbook ‘Introduction to Econometrics’ by James H. Stock and Mark W. Watson (2015). It gives a gentle introduction to the essentials of R programming and guides students in implementing the empirical applications presented throughout the textbook using the newly aquired skills. This is supported by interactive programming exercises generated with DataCamp Light and integration of interactive visualizations of central concepts which are based on the flexible JavaScript library D3.js." />
<meta name="twitter:image" content="https://www.econometrics-with-r.org//images/cover.png" />

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber, and Martin Schmelzer" />


<meta name="date" content="2023-07-12" />

<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black" />


<link rel="prev" href="2.1-simple-linear-regression.html"/>
<link rel="next" href="2.3-measures-of-fit.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<script src="js/hideOutput.js"></script>

<!-- Mathjax -->
<script type="text/javascript" id="MathJax-script" async
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/mml-chtml.min.js"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
extensions: ["tex2jax.js", "TeX/AMSmath.js"],
tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
jax: ["input/TeX","output/CommonHTML"]
});
MathJax.Hub.processSectionDelay = 0;
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script type="application/json" class="js-hypothesis-config">
{
"showHighlights": false
}
</script>
<script async defer src="https://hypothes.is/embed.js"></script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
{  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
clear: both;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



<div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

<div class="book-summary">
<nav role="navigation">

<ul class="summary">
<li><center><img src="images/logo.png" alt="logo" width="50%" height="50%"style="margin: 15px 0 0 0"></center></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-colophon.html"><a href="1.1-colophon.html"><i class="fa fa-check"></i><b>1.1</b> Colophon</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-a-very-short-introduction-to-r-and-rstudio.html"><a href="1.2-a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.2</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-lrwor.html"><a href="2-lrwor.html"><i class="fa fa-check"></i><b>2</b> Linear Regression with One Regressor</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-simple-linear-regression.html"><a href="2.1-simple-linear-regression.html"><i class="fa fa-check"></i><b>2.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="2.2" data-path="2.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>2.2</b> Estimating the Coefficients of the Linear Regression Model</a>
<ul>
<li class="chapter" data-level="" data-path="2.2-estimating-the-coefficients-of-the-linear-regression-model.html"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="2.3-measures-of-fit.html"><a href="2.3-measures-of-fit.html"><i class="fa fa-check"></i><b>2.3</b> Measures of Fit</a>
<ul>
<li class="chapter" data-level="" data-path="2.3-measures-of-fit.html"><a href="2.3-measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="2.3-measures-of-fit.html"><a href="2.3-measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="2.3-measures-of-fit.html"><a href="2.3-measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2.4-tlsa.html"><a href="2.4-tlsa.html"><i class="fa fa-check"></i><b>2.4</b> The Least Squares Assumptions</a>
<ul>
<li class="chapter" data-level="" data-path="2.4-tlsa.html"><a href="2.4-tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="2.4-tlsa.html"><a href="2.4-tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="2.4-tlsa.html"><a href="2.4-tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2.5-tsdotoe.html"><a href="2.5-tsdotoe.html"><i class="fa fa-check"></i><b>2.5</b> The Sampling Distribution of the OLS Estimator</a>
<ul>
<li class="chapter" data-level="" data-path="2.5-tsdotoe.html"><a href="2.5-tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="2.5-tsdotoe.html"><a href="2.5-tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="2.5-tsdotoe.html"><a href="2.5-tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="2.6-exercises-4.html"><a href="2.6-exercises-4.html"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-htaciitslrm.html"><a href="3-htaciitslrm.html"><i class="fa fa-check"></i><b>3</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="3.1-testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>3.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="3.2" data-path="3.2-cifrc.html"><a href="3.2-cifrc.html"><i class="fa fa-check"></i><b>3.2</b> Confidence Intervals for Regression Coefficients</a>
<ul>
<li class="chapter" data-level="" data-path="3.2-cifrc.html"><a href="3.2-cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-rwxiabv.html"><a href="3.3-rwxiabv.html"><i class="fa fa-check"></i><b>3.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="3.4" data-path="3.4-hah.html"><a href="3.4-hah.html"><i class="fa fa-check"></i><b>3.4</b> Heteroskedasticity and Homoskedasticity</a>
<ul>
<li class="chapter" data-level="" data-path="3.4-hah.html"><a href="3.4-hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="3.4-hah.html"><a href="3.4-hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="3.4-hah.html"><a href="3.4-hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-the-gauss-markov-theorem.html"><a href="3.5-the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>3.5</b> The Gauss-Markov Theorem</a>
<ul>
<li class="chapter" data-level="" data-path="3.5-the-gauss-markov-theorem.html"><a href="3.5-the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="3.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="3.6-using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>3.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="3.7" data-path="3.7-exercises-5.html"><a href="3.7-exercises-5.html"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

</nav>
</div>

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
</h1>
</div>

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">

<section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click "Annotate" in the pop-up menu. You can also see the annotations of others: click the arrow in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="estimating-the-coefficients-of-the-linear-regression-model" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Estimating the Coefficients of the Linear Regression Model<a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#estimating-the-coefficients-of-the-linear-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In practice, the intercept <span class="math inline">\(\beta_0\)</span> and slope <span class="math inline">\(\beta_1\)</span> of the population regression line are unknown. Therefore, we must employ data to estimate both unknown parameters. In the following, a real world example will be used to demonstrate how this is achieved. We want to relate test scores to student-teacher ratios measured in Californian schools. The test score is the district-wide average of reading and math scores for fifth graders. Again, the class size is measured as the number of students divided by the number of teachers (the student-teacher ratio). As for the data, the California School data set (<tt>CASchools</tt>) comes with an <tt>R</tt> package called <tt>AER</tt>, an acronym for <a href="https://cran.r-project.org/web/packages/AER/AER.pdf">Applied Econometrics with R</a> <span class="citation">(<a href="#ref-R-AER" role="doc-biblioref">Christian Kleiber and Zeileis 2022</a>)</span>. After installing the package with <tt>install.packages(“AER”)</tt> and attaching it with <tt>library(AER)</tt> the data set can be loaded using the function <tt>data()</tt>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="do">## # install the AER package (once)</span></span>
<span id="cb10-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="do">## install.packages(&quot;AER&quot;)</span></span>
<span id="cb10-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb10-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="do">## # load the AER package</span></span>
<span id="cb10-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AER)</span>
<span id="cb10-6"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># load the the data set in the workspace</span></span>
<span id="cb10-8"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(CASchools)</span></code></pre></div>
<p>Once a package has been installed it is available for use at further occasions when invoked with <tt>library()</tt> — there is no need to run <tt>install.packages()</tt> again!</p>
<p>It is interesting to know what kind of object we are dealing with.
<tt>class()</tt> returns the class of an object. Depending on the class of an object some functions (for example <tt>plot()</tt> and <tt>summary()</tt>) behave differently.</p>
<p>Let us check the class of the object <tt>CASchools</tt>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(CASchools)</span>
<span id="cb11-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;data.frame&quot;</span></span></code></pre></div>
<p>It turns out that <tt>CASchools</tt> is of class <tt>data.frame</tt> which is a convenient format to work with, especially for performing regression analysis.</p>
<p>With help of <tt>head()</tt> we get a first overview of our data. This function shows only the first 6 rows of the data set which prevents an overcrowded console output.</p>

<div class="rmdnote">
Press <tt>ctrl + L</tt> to clear the console. This command deletes any code that has been typed in and executed by you or printed to the console by <tt>R</tt> functions. The good news is that anything else is left untouched. You neither lose defined variables etc. nor the code history. It is still possible to recall previously executed <tt>R</tt> commands using the up and down keys. If you are working in <em>RStudio</em>, press <tt>ctrl + Up</tt> on your keyboard (<tt>CMD + Up</tt> on a Mac) to review a list of previously entered commands.
</div>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(CASchools)</span>
<span id="cb12-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   district                          school  county grades students teachers</span></span>
<span id="cb12-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    75119              Sunol Glen Unified Alameda  KK-08      195    10.90</span></span>
<span id="cb12-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    61499            Manzanita Elementary   Butte  KK-08      240    11.15</span></span>
<span id="cb12-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3    61549     Thermalito Union Elementary   Butte  KK-08     1550    82.90</span></span>
<span id="cb12-6"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4    61457 Golden Feather Union Elementary   Butte  KK-08      243    14.00</span></span>
<span id="cb12-7"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5    61523        Palermo Union Elementary   Butte  KK-08     1335    71.50</span></span>
<span id="cb12-8"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6    62042         Burrel Union Elementary  Fresno  KK-08      137     6.40</span></span>
<span id="cb12-9"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   calworks   lunch computer expenditure    income   english  read  math</span></span>
<span id="cb12-10"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1   0.5102  2.0408       67    6384.911 22.690001  0.000000 691.6 690.0</span></span>
<span id="cb12-11"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2  15.4167 47.9167      101    5099.381  9.824000  4.583333 660.5 661.9</span></span>
<span id="cb12-12"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3  55.0323 76.3226      169    5501.955  8.978000 30.000002 636.3 650.9</span></span>
<span id="cb12-13"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4  36.4754 77.0492       85    7101.831  8.978000  0.000000 651.9 643.5</span></span>
<span id="cb12-14"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5  33.1086 78.4270      171    5235.988  9.080333 13.857677 641.8 639.9</span></span>
<span id="cb12-15"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6  12.3188 86.9565       25    5580.147 10.415000 12.408759 605.7 605.4</span></span></code></pre></div>
<p>We find that the data set consists of plenty of variables and that most of them are numeric.</p>
<p>By the way: an alternative to <tt>class()</tt> and <tt>head()</tt> is <tt>str()</tt> which is deduced from ‘structure’ and gives a comprehensive overview of the object. Try!</p>
<p>Turning back to <tt>CASchools</tt>, the two variables we are interested in (i.e., average test score and the student-teacher ratio) are <em>not</em> included. However, it is possible to calculate both from the provided data. To obtain the student-teacher ratios, we simply divide the number of students by the number of teachers. The average test score is the arithmetic mean of the test score for reading and the score of the math test. The next code chunk shows how the two variables can be constructed as vectors and how they are appended to <tt>CASchools</tt>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute STR and append it to CASchools</span></span>
<span id="cb13-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb13-2" aria-hidden="true" tabindex="-1"></a>CASchools<span class="sc">$</span>STR <span class="ot">&lt;-</span> CASchools<span class="sc">$</span>students<span class="sc">/</span>CASchools<span class="sc">$</span>teachers </span>
<span id="cb13-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute TestScore and append it to CASchools</span></span>
<span id="cb13-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb13-5" aria-hidden="true" tabindex="-1"></a>CASchools<span class="sc">$</span>score <span class="ot">&lt;-</span> (CASchools<span class="sc">$</span>read <span class="sc">+</span> CASchools<span class="sc">$</span>math)<span class="sc">/</span><span class="dv">2</span>     </span></code></pre></div>
<p>If we ran <tt>head(CASchools)</tt> again we would find the two variables of interest as additional columns named <tt>STR</tt> and <tt>score</tt> (check this!).</p>
<p>Table 4.1 from the textbook summarizes the distribution of test scores and student-teacher ratios. There are several functions which can be used to produce similar results, e.g.,</p>
<ul>
<li><p><tt>mean()</tt> (computes the arithmetic mean of the provided numbers),</p></li>
<li><p><tt>sd()</tt> (computes the sample standard deviation),</p></li>
<li><p><tt>quantile()</tt> (returns a vector of the specified sample quantiles for the data).</p></li>
</ul>
<p>The next code chunk shows how to achieve this. First, we compute summary statistics on the columns <tt>STR</tt> and <tt>score</tt> of <tt>CASchools</tt>. In order to get nice output we gather the measures in a <tt>data.frame</tt> named <tt>DistributionSummary</tt>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute sample averages of STR and score</span></span>
<span id="cb14-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-2" aria-hidden="true" tabindex="-1"></a>avg_STR <span class="ot">&lt;-</span> <span class="fu">mean</span>(CASchools<span class="sc">$</span>STR) </span>
<span id="cb14-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-3" aria-hidden="true" tabindex="-1"></a>avg_score <span class="ot">&lt;-</span> <span class="fu">mean</span>(CASchools<span class="sc">$</span>score)</span>
<span id="cb14-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># compute sample standard deviations of STR and score</span></span>
<span id="cb14-6"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-6" aria-hidden="true" tabindex="-1"></a>sd_STR <span class="ot">&lt;-</span> <span class="fu">sd</span>(CASchools<span class="sc">$</span>STR) </span>
<span id="cb14-7"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-7" aria-hidden="true" tabindex="-1"></a>sd_score <span class="ot">&lt;-</span> <span class="fu">sd</span>(CASchools<span class="sc">$</span>score)</span>
<span id="cb14-8"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># set up a vector of percentiles and compute the quantiles </span></span>
<span id="cb14-10"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-10" aria-hidden="true" tabindex="-1"></a>quantiles <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.10</span>, <span class="fl">0.25</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.75</span>, <span class="fl">0.9</span>)</span>
<span id="cb14-11"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-11" aria-hidden="true" tabindex="-1"></a>quant_STR <span class="ot">&lt;-</span> <span class="fu">quantile</span>(CASchools<span class="sc">$</span>STR, quantiles)</span>
<span id="cb14-12"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-12" aria-hidden="true" tabindex="-1"></a>quant_score <span class="ot">&lt;-</span> <span class="fu">quantile</span>(CASchools<span class="sc">$</span>score, quantiles)</span>
<span id="cb14-13"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># gather everything in a data.frame </span></span>
<span id="cb14-15"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-15" aria-hidden="true" tabindex="-1"></a>DistributionSummary <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Average =</span> <span class="fu">c</span>(avg_STR, avg_score), </span>
<span id="cb14-16"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-16" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">StandardDeviation =</span> <span class="fu">c</span>(sd_STR, sd_score), </span>
<span id="cb14-17"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-17" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">quantile =</span> <span class="fu">rbind</span>(quant_STR, quant_score))</span>
<span id="cb14-18"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-19"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print the summary to the console</span></span>
<span id="cb14-20"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-20" aria-hidden="true" tabindex="-1"></a>DistributionSummary</span>
<span id="cb14-21"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               Average StandardDeviation quantile.10. quantile.25. quantile.40.</span></span>
<span id="cb14-22"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; quant_STR    19.64043          1.891812      17.3486     18.58236     19.26618</span></span>
<span id="cb14-23"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; quant_score 654.15655         19.053347     630.3950    640.05000    649.06999</span></span>
<span id="cb14-24"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             quantile.50. quantile.60. quantile.75. quantile.90.</span></span>
<span id="cb14-25"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; quant_STR       19.72321      20.0783     20.87181     21.86741</span></span>
<span id="cb14-26"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; quant_score    654.45000     659.4000    666.66249    678.85999</span></span></code></pre></div>
<p>As for the sample data, we use <tt>plot()</tt>. This allows us to detect characteristics of our data, such as outliers which are harder to discover by looking at mere numbers. This time we add some additional arguments to the call of <tt>plot()</tt>.</p>
<p>The first argument in our call of <tt>plot()</tt>, <tt>score ~ STR</tt>, is again a formula that states variables on the y- and the x-axis. However, this time the two variables are not saved in separate vectors but are columns of <tt>CASchools</tt>. Therefore, <tt>R</tt> would not find them without the argument <tt>data</tt> being correctly specified. <tt>data</tt> must be in accordance with the name of the <tt>data.frame</tt> to which the variables belong to, in this case <tt>CASchools</tt>. Further arguments are used to change the appearance of the plot: while <tt>main</tt> adds a title, <tt>xlab</tt> and <tt>ylab</tt> add custom labels to both axes.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(score <span class="sc">~</span> STR, </span>
<span id="cb15-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb15-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">data =</span> CASchools,</span>
<span id="cb15-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb15-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Scatterplot of Test Score and STR&quot;</span>, </span>
<span id="cb15-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb15-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;STR (X)&quot;</span>,</span>
<span id="cb15-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb15-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Test Score (Y)&quot;</span>)</span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-24-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The plot (Figure 4.2 in the book) shows the scatterplot of all observations on the student-teacher ratio and test score. We see that the points are strongly scattered, and that the variables are negatively correlated. That is, we expect to observe lower test scores in bigger classes.</p>
<p>The function <tt>cor()</tt> (see <tt>?cor</tt> for further info) can be used to compute the correlation between two <em>numeric</em> vectors.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(CASchools<span class="sc">$</span>STR, CASchools<span class="sc">$</span>score)</span>
<span id="cb16-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -0.2263627</span></span></code></pre></div>
<p>As the scatterplot already suggests, the correlation is negative but rather weak.</p>
<p>The task we are now facing is to find a line which best fits the data. Of course we could simply stick with graphical inspection and correlation analysis and then select the best fitting line by eyeballing. However, this would be rather subjective: different observers would draw different regression lines. On this account, we are interested in techniques that are less arbitrary. Such a technique is given by ordinary least squares (OLS) estimation.</p>
<div id="the-ordinary-least-squares-estimator" class="section level3 unnumbered hasAnchor">
<h3>The Ordinary Least Squares Estimator<a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The OLS estimator chooses the regression coefficients such that the estimated regression line is as “close” as possible to the observed data points. Here, closeness is measured by the sum of the squared mistakes made in predicting <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>. Let <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> be some estimators of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. Then the sum of squared estimation mistakes can be expressed as</p>
<p><span class="math display">\[ \sum^n_{i = 1} (Y_i - b_0 - b_1 X_i)^2. \]</span></p>
<p>The OLS estimator in the simple regression model is the pair of estimators for intercept and slope which minimizes the expression above. The derivation of the OLS estimators for both parameters are presented in Appendix 4.1 of the book. The results are summarized in Key Concept 4.2.</p>
<div id="KC4.2" class="keyconcept">
<h3 class="right">
Key Concept 4.2
</h3>
<h3 class="left">
The OLS Estimator, Predicted Values, and Residuals
</h3>
<p>
<p>The OLS estimators of the slope <span class="math inline">\(\beta_1\)</span> and the intercept <span class="math inline">\(\beta_0\)</span> in the simple linear regression model are
<span class="math display">\[\begin{align}
\hat\beta_1 &amp; = \frac{ \sum_{i = 1}^n (X_i - \overline{X})(Y_i - \overline{Y}) } { \sum_{i=1}^n (X_i - \overline{X})^2},  \\
\\
\hat\beta_0 &amp; =  \overline{Y} - \hat\beta_1 \overline{X}.
\end{align}\]</span>
The OLS predicted values <span class="math inline">\(\widehat{Y}_i\)</span> and residuals <span class="math inline">\(\hat{u}_i\)</span> are
<span class="math display">\[\begin{align}
\widehat{Y}_i &amp; =  \hat\beta_0 + \hat\beta_1 X_i,\\
\\
\hat{u}_i &amp; =  Y_i - \widehat{Y}_i.
\end{align}\]</span></p>
The estimated intercept <span class="math inline">\(\hat{\beta}_0\)</span>, the slope parameter <span class="math inline">\(\hat{\beta}_1\)</span> and the residuals <span class="math inline">\(\left(\hat{u}_i\right)\)</span> are computed from a sample of <span class="math inline">\(n\)</span> observations of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(Y_i\)</span>, <span class="math inline">\(i\)</span>, <span class="math inline">\(...\)</span>, <span class="math inline">\(n\)</span>. These are <em>estimates</em> of the unknown population intercept <span class="math inline">\(\left(\beta_0 \right)\)</span>, slope <span class="math inline">\(\left(\beta_1\right)\)</span>, and error term <span class="math inline">\((u_i)\)</span>.
</p>
<p>The formulas presented above may not be very intuitive at first glance. The following interactive application aims to help you understand the mechanics of OLS. You can add observations by clicking into the coordinate system where the data are represented by points. Once two or more observations are available, the application computes a regression line using OLS and some statistics which are displayed in the right panel. The results are updated as you add further observations to the left panel. A double-click resets the application, i.e., all data are removed.</p>
<iframe height="410" width="900" frameborder="0" scrolling="no" src="SimpleRegression.html">
</iframe>
</div>
<p>There are many possible ways to compute <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> in <tt>R</tt>. For example, we could implement the formulas presented in Key Concept 4.2 with two of <tt>R</tt>’s most basic functions: <tt>mean()</tt> and <tt>sum()</tt>. Before doing so we <em>attach</em> the <tt>CASchools</tt> dataset.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">attach</span>(CASchools) <span class="co"># allows to use the variables contained in CASchools directly</span></span>
<span id="cb17-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># compute beta_1_hat</span></span>
<span id="cb17-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-4" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> <span class="fu">sum</span>((STR <span class="sc">-</span> <span class="fu">mean</span>(STR)) <span class="sc">*</span> (score <span class="sc">-</span> <span class="fu">mean</span>(score))) <span class="sc">/</span> <span class="fu">sum</span>((STR <span class="sc">-</span> <span class="fu">mean</span>(STR))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb17-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># compute beta_0_hat</span></span>
<span id="cb17-7"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-7" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(score) <span class="sc">-</span> beta_1 <span class="sc">*</span> <span class="fu">mean</span>(STR)</span>
<span id="cb17-8"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print the results to the console</span></span>
<span id="cb17-10"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-10" aria-hidden="true" tabindex="-1"></a>beta_1</span>
<span id="cb17-11"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -2.279808</span></span>
<span id="cb17-12"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-12" aria-hidden="true" tabindex="-1"></a>beta_0</span>
<span id="cb17-13"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 698.9329</span></span></code></pre></div>

<div class="rmdknit">
<p>Calling <tt>attach(CASchools)</tt> enables us to address a variable contained in <tt>CASchools</tt> by its name: it is no longer necessary to use the <tt>$</tt> operator in conjunction with the dataset: <tt>R</tt> may evaluate the variable name directly.</p>
<tt>R</tt> uses the object in the user environment if this object shares the name of variable contained in an attached database. However, it is a better practice to always use distinctive names in order to avoid such (seeming) ambivalences!
</div>
<p><br></p>
<p><strong>Notice that we address variables contained in the attached dataset <tt>CASchools</tt> directly for the rest of this chapter!</strong></p>
<p>Of course, there are even more manual ways to perform these tasks. With OLS being one of the most widely-used estimation techniques, <tt>R</tt> of course already contains a built-in function named <tt>lm()</tt> (<strong>l</strong>inear <strong>m</strong>odel) which can be used to carry out regression analysis.</p>
<p>The first argument of the function to be specified is, similar to <tt>plot()</tt>, the regression formula with the basic syntax <tt>y ~ x</tt> where <tt>y</tt> is the dependent variable and <tt>x</tt> the explanatory variable. The argument <tt>data</tt> determines the data set to be used in the regression. We now revisit the example from the book where the relationship between the test scores and the class sizes is analyzed. The following code uses <tt>lm()</tt> to replicate the results presented in figure 4.3 of the book.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate the model and assign the result to linear_model</span></span>
<span id="cb18-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-2" aria-hidden="true" tabindex="-1"></a>linear_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> STR, <span class="at">data =</span> CASchools)</span>
<span id="cb18-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># print the standard output of the estimated lm object to the console </span></span>
<span id="cb18-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-5" aria-hidden="true" tabindex="-1"></a>linear_model</span>
<span id="cb18-6"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-7"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb18-8"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = score ~ STR, data = CASchools)</span></span>
<span id="cb18-9"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-10"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb18-11"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)          STR  </span></span>
<span id="cb18-12"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      698.93        -2.28</span></span></code></pre></div>
<p>Let us add the estimated regression line to the plot. This time we also enlarge the ranges of both axes by setting the arguments <tt>xlim</tt> and <tt>ylim</tt>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the data</span></span>
<span id="cb19-2"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(score <span class="sc">~</span> STR, </span>
<span id="cb19-3"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">data =</span> CASchools,</span>
<span id="cb19-4"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Scatterplot of Test Score and STR&quot;</span>, </span>
<span id="cb19-5"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;STR (X)&quot;</span>,</span>
<span id="cb19-6"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Test Score (Y)&quot;</span>,</span>
<span id="cb19-7"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">30</span>),</span>
<span id="cb19-8"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">600</span>, <span class="dv">720</span>))</span>
<span id="cb19-9"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># add the regression line</span></span>
<span id="cb19-11"><a href="2.2-estimating-the-coefficients-of-the-linear-regression-model.html#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(linear_model) </span></code></pre></div>
<p><img src="ITER_files/figure-html/unnamed-chunk-30-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Did you notice that this time, we did not pass the intercept and slope parameters to <tt>abline</tt>? If you call <tt>abline()</tt> on an object of class <tt>lm</tt> which only contains a single regressor, <tt>R</tt> draws the regression line automatically!</p>
</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-R-AER" class="csl-entry">
Kleiber, Christian, and Achim Zeileis. 2022. <em><span class="nocase">AER: Applied Econometrics with R</span></em> (version 1.2-10). <a href="https://CRAN.R-project.org/package=AER">https://CRAN.R-project.org/package=AER</a>.
</div>
</div>
</section>

</div>
</div>
</div>
<a href="2.1-simple-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="2.3-measures-of-fit.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
</div>
</div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/mca91/EconometricsWithR/edit/master/04-ch4.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ITER.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
var script = document.createElement("script");
script.type = "text/javascript";
var src = "true";
if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
if (location.protocol !== "file:")
if (/^https?:/.test(src))
src = src.replace(/^https?:/, '');
script.src = src;
document.getElementsByTagName("head")[0].appendChild(script);
})();
</script>
</body>

</html>
